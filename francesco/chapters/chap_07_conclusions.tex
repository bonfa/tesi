\chapter{Conclusions}
	The objective of this work is to develop a software module which receives images as input and analyzes them by extracting particular information like the shapes they contain, their colors and their positions and communicates them to \mbox{ACT-R} when the cognitive architecture requests it. 
	The ultimate purpose of this is to create a vision module for the cognitive architecture in order to make its visual perception as similar as possible to human one.
	

	The developed software uses \mbox{OpenCV} library to implement the visual operations and communicates the information to \mbox{ACT-R} thanks to a client-server communication method. 
	This solution is simple, fast and allows to use a library which provides ready and tested functions for computer vision.  


	The software at the moment recognizes quadrilaterals, circles and triangles and makes qualitative and quantitative evaluations about colors, relative positions and dimensions of the objects. 
	In particular, the tool is used in the Rush Hour experiment for analyzing the input image, extracting the list of objects it contains and communicating it to \mbox{ACT-R}. 
	In this way the cognitive architecture does not start working from a list of objects but it processes directly the images.
	This fact provides \mbox{ACT-R} with the possibility of processing the data directly in the real world and approaches its perception to human one. 	
		

	The restricted number of features offered by the visual module at the moment represents the biggest limit of this solution.
	However, it is enough to add new functions to this tool in order to extend more and more the scope of this module and use it increasingly together with \mbox{ACT-R}.


	In order to adapt the system to work with other experiments, the first improvements that can be done are adding the recognition of new kinds of shape, for example ellipses, and a tool for \emph{{Optical Character Recognition\footnote{An Optical Character Recognition, also known as OCR, is a software which recognizes and decodes text in images.}}}.
	In fact, at the moment, images used in the experiments conducted with the cognitive architecture, in general are quite simple.
	They normally contain only shapes and may include some text.
	The introduction of methods for recognizing new shapes and text makes the system more scalable with the definition  of new experiments that need to process images.


	Adding new functions for object recognition can lead to interesting applications in many research fields, in particular in the cognitive science and the spatial reasoning. 
	An example of this comes directly from the Center for Cognitive Science of the university of Freiburg.
	In fact, the team in which the author of this work has been inserted in developed a system for robots navigation with landmarks inside buildings. 
	The robot, together with the vision module, is able to identify a landmark, move close to it, decode the information it stores and send it to \mbox{ACT-R}, which can then communicate the robot how to behave.
	Adding new features to the Visual Module will make the scope of the solution wider so that it can be used in many and many experiments.
	This can improve the research in the field of spatial reasoning and, more generally, of cognitive science.


	In conclusion, the innovation of this software module consists in providing \mbox{ACT-R} with the possibility of processing images directly in the real world.
	This overcomes one of the biggest limits of the cognitive architecture: working in a virtual environment.
	Shifting the vision tasks to the computer vision library brings an immediate advantage: it allows to use ready and tested solutions to accomplish many visual tasks.
	Moreover, as the computer vision research field is very active and it produces continuously new solutions, always new possibilities will be available for visual experiments with the cognitive architecture.
	For all these reasons, the development of this module opens a wide range of possibility for the research in the field of cognitive science.




